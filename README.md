# Gavagai: Engineering Rational Artificial Agents

Inspired by Quine and Davidson, Gavagai explores how agents can learn *belief*, *desire*, and *intention* not as predefined states, but as emergent patterns from empirical learning. This project aims to:

- Represent propositional attitudes holophrastically
- Anchor meaning through intersubjective triangulation
- Model rational normativity and interpretive understanding

> “Meaning is not in the head. It is in the act of interpretation.”

## Project Overview
Gavagai is an ambitious research project to engineer an artificial agent whose behavior can be described in terms of propositional attitudes—beliefs, desires, intentions—drawing on the philosophical insights of Donald Davidson and W.V.O. Quine. The goal is not simply to classify text or generate language, but to build a system whose actions and outputs fit into normatively rational patterns, making psychological (intentional) descriptions true of it, not just mechanistic or physical ones.

## Philosophical Foundations
- **Rational Structure**: Psychological descriptions (belief, desire, intention) impose a rational structure on behavior, supervening on but not reducible to physical mechanisms.
- **Normativity**: The agent should act in ways that fit rational patterns, not just produce sentences. Outputs should be interpretable as rational, intentional actions.
- **Radical Interpretation**: The agent should be capable of radical interpretation—assigning propositional attitudes to others and itself through intersubjective triangulation.
- **Naturalism**: Language and thought emerge from social interaction and environmental triangulation, not from innate mechanisms or internal representations alone.
- **Compositional Semantics**: The project explores how LLMs can move beyond stochastic text generation to simulate the logical and recursive constraints of rational, intentional descriptions.

## Roadmap
1. **Project Overhaul**: Remove legacy code focused on simple text classification. Refactor to align with the new philosophical and engineering goals.
2. **Literature Review**: Summarize key works by Davidson, Quine, and related thinkers. Identify computational analogues and prior work.
3. **Design Principles**: Formalize requirements for rational, intentional behavior in artificial agents. Define evaluation criteria.
4. **Prototype Development**: Explore architectures that support radical interpretation, normativity, and compositional semantics.
5. **Iterative Testing**: Develop benchmarks and tests for rational patterning and intentional ascription.
6. **Documentation**: Maintain clear philosophical and technical documentation for all contributors.

## Getting Started

### Installation

```bash
git clone https://github.com/yourusername/gavagai.git
cd gavagai
pip install -e .
```

### Creating Annotations

You can create new annotations using the interactive tool:

```bash
python scripts/create_annotation.py
```

See [Annotation Format Documentation](docs/annotation_format.md) for details on the annotation format.

---

## Contributing
See `INSTRUCTIONS.md` for the philosophical background and guiding principles. Contributions should align with the project's rationalist and naturalist orientation.

*This project is a work in progress. All code, documentation, and design decisions should be guided by the philosophical framework outlined above.*
